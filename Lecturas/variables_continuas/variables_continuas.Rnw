\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{bigints}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\usepackage{amsmath} 
\usepackage{mathtools}
%\usepackage[spanish]{babel}
\usepackage{latexsym}
\geometry{verbose,tmargin=1.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfig}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bb}[1]{\textbf{#1}}
\DeclareMathOperator{\rank}{\textbf{rango}}
\DeclareMathOperator{\proy}{\textbf{proy}}
\DeclareMathOperator{\nulll}{\textbf{nul}}
\DeclareMathOperator{\diag}{\textbf{diag}}
\DeclareMathOperator{\col}{\textbf{col}}
\DeclareMathOperator{\fila}{\textbf{fila}}
\DeclareMathOperator{\dimm}{dim}
\DeclareMathOperator{\Traz}{Tr}
%\theoremstyle{definition}
\everymath{\displaystyle}
\newtheorem{ejemplo}{{Ejemplo }}[section]
\newtheorem{defi}{{Definici\'on}}[section]
\newtheorem{teo}{{Teorema}}[section]
\newtheorem{pros}{{Proposici\'on}}[section]
\newtheorem{cor}{{Corolario}}[section]
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
library(ggplot2)
library(grid)
#library(animation)
# set global chunk options
opts_chunk$set(fig.path='figure/minimal-', fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE,width=90)
@

%\title{\underline{\textbf{Notas de mat\'ematica}}}
%\date{}
%\maketitle
\hspace*{0.5\linewidth}
\begin{minipage}{0.6\linewidth}
Curso: C\'alculo de probabilidades CM-1H2\par
Variables aleatorias \par
\end{minipage}


\vspace {0.5cm}

\section {Variables aleatorias continuas}

En muchos modelos probabil\'isticos, las salidas o resultados son num\'ericos, por ejemplos, las lecturas de instrumentos o el precio de las acciones. En otros experimentos, las salidas no son num\'ericas, pero pueden estar asociadas a un valor num\'erico. Por ejemplo, si el experimento es la selecci\'on de estudiantes desde una poblaci\'on, podemos considerar su promedio de calificaciones.  Cuando tratamos con esos valores num\'ericos, es a menudo \'util asignarles una probabilidad. Esto se puede hacer con la noci\'on de \textbf{variable aleatoria}.

\vspace{0.2cm}

Las variables aleatorias continuas toman valores en un intervalo continuo. Por ejemplo, una variable aleatoria que representa el tiempo entre dos llegadas sucesivas de un sistema de colas, o la  que representa la temperatura en un reactor nuclear, es un ejemplo de una variable aleatoria continua.

El tiempo en el primer caso, o temperatura en el segundo, son reales pertenecientes a un subconjunto continuo del sistema de n\'umeros reales. Las variables aleatorias que representan cantidades como tiempo, temperatura, distancia, \'area, volumen, etc,  pueden discretizarse en minutos, horas, yardas, millas, etc., en cuyo caso es apropiado utilizar variables aleatorias discretas para representalos.

\vspace{0.2cm}

\begin{ejemplo}
\normalfont Consideremos un experimento aleatorio de lanzar un dardo en un tablero circular, sin salirse del tablero. Asumiendo que el radio del tablero es $1$, el espacio muestral es el conjunto de pares ordenados dentro del c\'irculo unitario

\[
\Omega=\left\{(x,y)\,:\, x,y\in\mathbb{R}, \,\sqrt{x^2+y^2} < 1\right\}.
\]

y el evento que describe un golpe en el tablero  es dado por: 

\[
E=\left\{(x,y)\, : \,x,y\in\mathbb{R}, \,\sqrt{x^2+y^2} < 0.1\right\}\subset\Omega.
\]

La variable aleatoria $R$ definida como $R(x,y) = \sqrt{x^2 + y^2}$ representa la distancia entre la posici\'on del dardo y y el origen. Como $\mathbb{P}(R =r) = 0$, desde que $\{R = r \} = 0$, para todo $r$. Tambi\'en tenemos que:

\begin{align*}
\mathbb{P}(R < r) &=  \mathbb{P}\left(\left\{(x,y):x,y\in\mathbb{R}, \sqrt{x^2+y^2} < r\right\}\right) = \frac{\pi r^2}{\pi 1^2}=r^2 \\
\mathbb{P}(0.2 < R < 0.5) &= \mathbb{P}\left(\left\{(x,y):x,y\in\mathbb{R}, 0.2 < \sqrt{x^2+y^2} < 0.5\right\}\right)\\ &=\frac{\pi (0.5^2-0.2^2)}{\pi 1^2}.
\end{align*}
\end{ejemplo}


\vspace{0.3cm}

\subsection{Funci\'on de densidad de probabilidad para una variable aleatoria continua}

 \vspace{0.2cm}
 
 Para una variable aleatoria continua $X$, la funci\'on definida como:
 
 \[
 f_X(x) = dF_X(x)/dx
 \]
 
 \vspace{0.2cm}
 
 Es llamada \texttt{funci\'on de densidad de probabilidad de  X (PDF)}. Esta funci\'on cumple el mismo papel para una variable aleatoria continua que el papel desempe\~nado por la funci\'on de masa de probabilidad de una variable aleatoria discreta. En este caso, la suma utilizada anteriormente se sustituye por la integraci\'on. Vemos este caso:
 
 \[
 f_X(x) = \lim_{\Delta x \rightarrow 0}\frac{F_X(x + \Delta x) - F_X(x)}{\Delta x} = \lim_{\Delta x \rightarrow 0}\frac{\mathbb{P}(x < X \leq x+  \Delta x )}{\Delta x}.
 \]
 
 \vspace{0.2cm}
 
 As\'i, cuando $\ x$ es peque\~no, tenemos
 
 \vspace{0.2cm}
 
 \[
 f_X(x)\Delta x \approx \mathbb{P}(x < X \leq x + \Delta x)
 \]
 
 \vspace{0.2cm}
 
 Esto es $f_X(x)\Delta x$ es aproximadamente igual a la probabilidad de que $X$ pertenece al intervalo, $(x, x + \Delta x]$. Si $\Delta x$ tiende al infinitesimal  $dx$, podemos escribir:
 
 \vspace{0.2cm}
 
 \[
 \mathbb{P}(x < X \leq x + dx) = f_X(x)dx.
 \]
 
 
 \vspace{0.2cm}
 
 Se sigue que $f_X(x) \geq 0$ para todo $x$.
 
 \vspace{0.2cm}
 
 Si conocemos la funci\'on densidad de una variable aleatoria continua, podemos obtener la funci\'on de distribuci\'on acumulativa por integraci\'on:
 
 \vspace{0.2cm}
 
 \[
 F_X(x) = \mathbb{P}(X \leq x) = \bigints_{-\infty}^{x}f_X(t)dt\ \ \ \text{para}\ \ -\infty < x < \infty.
 \]
 
 \vspace{0.2cm}
 
 Desde que $F_X(\infty) = 1$  se sigue que:
 
 \vspace{0.2cm}
 
 \[
 \bigints_{-\infty}^{\infty}f_X(x) dx = 1.
 \]
 
 \vspace{0.2cm}
 
 A partir de estas consideraciones, podemos afirmar que una funci\'on $f_X(x)$ es la funci\'on de densidad de probabilidad para alguna variable aleatoria continua si y s\'olo si satisface las dos propiedades:
 
 \vspace{0.2cm}
 
 \[
 f_X(x) \geq 0\ \ \ \text{para todo }\ \ x \in \mathbb{R}.
 \]
 
 y 
 
 \[
 \bigints_{-\infty}^{\infty}f_X(x) dx = 1.
 \]
 
 \vspace{0.2cm}
 
 La probabilidad que $X$ se encuentra en el intervalo $(a, b]$, es obtenido desde:
 
 \vspace{0.2cm}
 
 \begin{align*}
 \mathbb{P}(X \in (a, b]) = \mathbb{P}(a < X \leq b) = \mathbb{P}(X \leq b) - \mathbb{P}(X \leq a)\\
 = \bigints_{-\infty}^{b}f_X(t) dt - \bigints_{-\infty}^{a}f_X(t) dt = \bigints_{a}^{b}f_X(t) dt.
 \end{align*}
 
 \vspace{0.2cm}
 
 Por lo tanto, la probabilidad de que la variable aleatoria se encuentre en un intervalo dado en el eje real es igual al \'area bajo la curva de densidad de probabilidad en este intervalo.
 
 
 \vspace{0.4cm}
 
 \underline{La relaci\'on entre el CDF y el PDF se muestra en las siguientes ecuaciones:}
 
 \begin{align*}
f_X(r)&= \begin{cases} F_X'(r)& F_X'(r)\text{ existe}\\ 0 & \text{en otros casos}\end{cases} \\
F_X(x)&=\bigints_{-\infty}^x f_X(r)\,dr.
\end{align*}
 
donde la primera ecuaci\'on se sigue de la definici\'on de un PDF y la segunda l\'inea se sigue del teorema fundamental del c\'alculo.
 
 \vspace{0.3cm}
 
\begin{ejemplo}
  
\normalfont Sup\'ongase que $X$ tiene \texttt{PDF}

\vspace{0.2cm}

\[
f_X(x) = \begin{cases}
1 & \mbox{para} \ \ 0 \leq x < 1 \\
0 & \mbox{en otros casos}
\end{cases}
\]


\vspace{0.2cm}

Claramente $f_{X} \geq 0$ y $\int f_X(x)dx = 1$. Una variable aleatoria con esta densidad se dice que tiene una distribuci\'on uniforme (\mbox{Uniform(0,1)}), lo que captura la idea, de escoger un punto entre $0$ y $1$.  El \texttt{CDF} est\'a dado por

\vspace{0.2cm}

\[
F_{X}(x) = \begin{cases}
0 & x < 0\\
x & 0 \leq x \leq 1\\
1 & x > 1.
\end{cases}
\]

y cuyo gr\'afico es 

\begin{figure}[ht]
\centering
\includegraphics[scale=.55]{v0.png}
%\caption{Modelo del problema}
\end{figure}
\end{ejemplo}
 \vspace{0.2cm}

\begin{ejemplo}

\normalfont Supongamos que $X$ tiene \texttt{PDF}

\[
f_X(x) = \begin{cases}
0 & \mbox{si} \  x < 0\\
\frac{1}{(1 + x)^2} & \mbox{en otros casos}.
\end{cases}
\]

\vspace{0.2cm}

Desde que $\bigints f_X(x)dx = 1$ esta expresi\'on  es una bien definida \texttt{PDF}.

\end{ejemplo}

\vspace{0.3cm}

Las variables aleatorias pueden traer confusi\'on. Primero debes notar que si $X$ es continua entonces $\mathbb{P}(X = x) = 0$, para cada $x$. No debes tratar de pensar que $f(x)$ es $\mathbb{P}(X =x)$, esto s\'olo es v\'alido para variables aleatorias discretas. 

\vspace{0.2cm}

Obtenemos probabilidades de un PDF integrando. Un PDF puede ser mayor que 1 (a diferencia de una funci\'on de masa). 

\vspace{0.2cm}

Por ejemplo, si $f_X(x)= 5$ para $x \in [0, 1/5]$ y $0$ en otros  casos, entonces $f_X(x) \geq 0$ y $\bigints f_X(x)dx = 1$, por lo que este es un PDF bien definido aunque $f_X(x) = 5$ en algunos lugares.

\vspace{0.2cm}

En efecto un PDF puede ser no acotado. Por ejemplo si $f_X(x) = (2/3)x^{-1/3}$ para $0 < x < 1$ y $f(x) = 0$ en otros casos, entonces  $\bigints f_X(x)dx = 1$ incluso si $f_X$ no es acotada.

\vspace{0.3cm}

\begin{ejemplo}
\normalfont Sea 

\[
f_X(x) = \begin{cases}
0 & x < 0\\
\frac{1}{(1 + x)} & \mbox{ en otros casos.}
\end{cases}
\]

\vspace{0.2cm}

Esto no es un \texttt{PDF}, desde que $\int f_X(x)dx = \log \infty = \infty$.

\end{ejemplo}

\vspace{0.3cm}

Sea $F$ el \texttt{CDF} una variable aleatoria $X$, entonces:

\begin{itemize}
\item $\mathbb{P}(x < X \leq y) = F_X(y) -F_X(x)$
\item $\mathbb{P}(X > x) = 1-F_X(x)$
\item Si $X$ es continua, entonces
\begin{align*}
F_X(b) -F_X(a) = \mathbb{P}(a < X < b) &= \mathbb{P}(a \leq X < b)\\
 = \mathbb{P}(a < X \leq b) &=  \mathbb{P}(a \leq X \leq b)
\end{align*}
\end{itemize}

\vspace{0.5cm}

\begin{defi}
\normalfont Sea $X$ una variable aleatoria con \texttt{CDF} $F_X$. La \texttt{inversa \texttt{CDF}} o \texttt{funci\'on cuantil} es definida como:


\[
F_X^{-1}(q) = \inf\{x: F_X(x) > q \}
\]

\vspace{0.2cm}

para $q \in [0,1]$. Si $F_X$ es estrictamente creciente y continua, entonces $F_X^{-1}(q)$ es el \'unico n\'umero real $x$ tal que $F_X(x) = q$.

\end{defi}
\vspace{0.3cm}

Llamamos $F_X^{-1}(1/4)$ el \texttt{ primer cuartil}, $F_X^{-}(1/2)$ la \texttt{mediana} o \texttt{segundo cuartil} y $F_X^{-1}(3/4)$, el tercer cuartil.

\vspace{0.3cm}

Dos variables aleatorias $X$ y $Y$ son \textbf{iguales en distribuci\'on} si $F_{X}(x) = F_{Y}(y)$ para todo $x$. Esto significa que las aseveraciones de probabilidad acerca de $X$ y $Y$ deben ser las mismas, pero de ninguna manera que $X$ e $Y$ sean iguales. Supongamos por ejemplo $\mathbb{P}(X = 1) = \mathbb{P}(X = -1) =1/2$. Sea $Y = -X$. Entonces  $\mathbb{P}(Y = 1) = \mathbb{P}(Y = -1) =1/2$ y as\'i,  $X$ e $Y$ son iguales en distribuci\'on, pero no son iguales. En efecto $\mathbb{P}(X = Y) = 0$. 

\vspace{0.2cm}

Es tradicional escribir $X \sim  F$ para indicar que $X$ tiene una distribuci\'on $F$. Esto es una notaci\'on lamentable ya que el s\'imbolo $\sim $ tambi\'en se usa para denotar una aproximaci\'on.  L\'ease $X \sim F$ como \texttt{X tiene una distribuci\'on F} y no como \texttt{X es aproximadamente F}.

\subsection {Funciones de variables aleatorias}


\vspace{0.3cm}

Como se sabe, una variable aleatoria $X$ es una funci\'on que asigna valores de $\R$ para cada resultado o salida de un espacio muestral. Dada una variable aleatoria $X$ podemos definir otras variables aleatorias que son funciones de $X$. Por ejemplo, la variable aleatoria $Y$ definida como  $2X$ toma cada resultado en el espacio muestral y le asigna un real que es igual al doble del valor que $X$ le asigna. La variable aleatoria $Y = X^2$ asigna un resultado que es el cuadrado del valor que $X$ le asigna y as\'i sucesivamente.

\vspace{0.2cm}

En general, si una variable aleatoria $X$ asigna el valor $x$ a un resultado y si $g(X)$ es una funci\'on de $X$, entonces $Y = g(X)$ es una variable aleatoria y se le asigna el valor $g(x)$ a ese resultado. Se dice que la variable aleatoria $Y$ es una variable aleatoria derivada. Esto es, si $X$ es una variable aleatoria, entonces $X^2, e^X$ y $\sin(X)$ son variables aleatorias, como $g(X)$ para una funci\'on $g : \R \rightarrow \R$.

\vspace{0.2cm}


Por ejemplo, imaginemos que  dos equipos de baloncesto ($A$ y $B$) est\'an jugando un partido de siete partidos, y que X sea el n\'umero de victorias para el equipo $A$ (as\'i que $X \sim  \texttt{Binomial}(7,1/2)$ si los equipos est\'an igualados y los juegos son independientes). Sea $g(x) = 7$ y $h(x) = 1$ si $x\geq 4$ y $h(x) = 0$ si $x < 4$. Entonces $g(X) = 7 -X$  es el n\'umero de victorias para el equipo $B$ y $h(X)$ es el indicador de que el equipo $A$ gana la mayor\'ia de los juegos. Puesto que $X$ es una variable aleatoria,  $g(X)$ y  $h(X)$ son tambi\'en variables aleatorias.

\begin{defi}
\normalfont Para un experimento con un espacio muestral $\Omega$, una variable aleatoria $X$ y una funci\'on  $g : \R \rightarrow \R$, $g(X)$ es una variable aleatoria que mapea $s$ a $g(X(s)$ para todo $s \in \Omega$.
\end{defi}

\vspace{0.2cm}

Sea $g(X) = \sqrt{X}$, la siguiente figura muestra que $g(X)$ es la composici\'on de las funciones $X$ y $g$.En esta figura, la variable aleatoria $X$ es definida sobre un espacio muestral con $6$ elementos y tiene los posibles valores $0, 1$ y $4$. La funci\'on $g$ es la ra\'iz cuadrada. Componiendo $X$ y $g$ nos da la variable aleatoria $g(X) = \sqrt{X}$ que tiene los valores $0, 1$ y $2$.
 
\vspace{0.3cm}

\begin{figure}[ht]
\centering
\includegraphics[width=13cm]{v1}
\end{figure}


\vspace{0.2cm}


Consideremos ahora el caso de una variable aleatoria discreta $X$ cuya funci\'on de masa de probabilidad es $p_X(x)$. Dada una funci\'on $g(X)$ de $X$, nos gustar\'ia encontrar la funci\'on de masa de probabilidad de la variable aleatoria $Y = g(X)$, es decir, buscamos encontrar $p_Y(y)$.

\vspace{0.3cm}

\begin{ejemplo}

\normalfont Sea $X$ una variable aleatoria discreta con funci\'on de probabilidad, dada por,

\[
p_X(x) = \begin{cases}
1/10 & x = 1, \\
2/10 & x = 2, \\
3/10 & x = 3, \\
4/10 & x = 4, \\
0 & \text{en otros casos.}
\end{cases}
\]

\vspace{0.2cm}

Con esta variable aleatoria, cada resultado en el espacio muestral es mapeado a uno de los cuatro n\'umeros reales $1$, $2$, $3$ o $4$. Considere ahora la variable aleatoria $Y = 2X$. En este caso cada resultado se mapea en uno de los enteros $2$, $4$, $6$ y  $8$. Pero ?` qu\'e pasa con la funci\'on de masa de probabilidad de Y?.

\vspace{0.2cm}

Es evidente que, si la probabilidad de que $X$ asigne un resultado en $1$ sea $1/10$, entonces la probabilidad de que $Y$ asigne  un resultado en $2$ tambi\'en debe ser $1/10$, si $X$ otra vez  asigna un resultado en $2$ con probabilidad $2/10$, entonces, esta debe ser  tambi\'en  la probabilidad de que $Y$ asigne un resultado en $4$ y as\'i sucesivamente. En este ejemplo espec\'ifico, tenemos:

\vspace{0.2cm}

\[
p_Y(y) = \mathbb{P}(Y = g(x)) = \mathbb{P}(X =x) = p_X(x).
\]

\end{ejemplo}

\vspace{0.2cm}

El caso anterior se da cuando  $g$ es una funci\'on  uno a uno o inyectiva. El caso en el que $Y=g(X)$ con $g$ inyectiva se ilustra en las siguientes  tablas:

\begin{figure}[ht]%
    \centering
    \subfloat[PMF de X]{{\includegraphics[width=5cm]{v2}}}
    \qquad
    \subfloat[PMF de Y]{{\includegraphics[width=5cm]{v3}}}
\end{figure}

\vspace{0.2cm}

La idea es que si los distintos valores posibles de $X$ son $x_1, x 2, \dots $ con probabilidades
$p_1, p_2,\dots $ (respectivamente), entonces los distintos valores posibles de $Y$ son $g(x_1), g(x_2),\dots$, con la misma lista $p_1, p_2, \dots$, de probabilidades.
 
 
\begin{ejemplo}
\normalfont Una part\'icula se mueve $n$ pasos en una l\'inea num\'erica. La part\'icula comienza en $0$ y en cada paso se  mueve $1$ unidad a la derecha o a la izquierda, con probabilidades iguales. Supongamos que todos los pasos son independientes. Sea $Y$ la posici\'on de la part\'icula despu\'es de $n$ pasos. Hallemos  el  PMF de $Y$.

\vspace{0.2cm}

En efecto si consideramos cada paso como un  ensayo de Bernoulli, donde ir por la  derecha se considera un \'exito e ir a la izquierda se considera un fracaso. Entonces el n\'umero de pasos que la part\'icula toma a la derecha es una variable aleatoria $\texttt{Binomial}(n, 1/2)$, que podemos nombrar como  $X$. Si $X = j$, entonces la part\'icula ha tomado $j$ pasos a la derecha y $n -j$ pasos a la izquierda, dando una posici?n final de $j - (n -j) = 2j -n$. As\'i podemos expresar  $Y$ como una funci\'on inyectiva de $X$, a saber $Y = 2X -n$ y desde que $X$ toma valores en $\{0,1, 2,\dots, n \}$, $Y$ toma valores en $\{-n, 2 -n, 4 -n, \dots, n \}$.

\vspace{0.2cm}

El PMF de $Y $ puede ser calculado desde el PMF de $X$:


\vspace{0.2cm}

\[
\mathbb{P}(Y =k) = \mathbb{P}(2X- n = k) = \mathbb{P}(X = (n + k)/2) = \binom{n}{\frac{n +k}{2}}\biggl(\frac{1}{2}\biggr)^n.
\]

si $k$ es un entero entre $-n$ y $n$ (inclusive) tal que $n + k$ es un n\'umero par.
\end{ejemplo}

\vspace{0.2cm}

Sin embargo, como muestra el siguiente ejemplo, no siempre se da el anterior caso:

\vspace{0.2cm}

\begin{ejemplo}
\normalfont Sea $X$ una variable aleatoria discreta, con una  funci\'on de masa de probabilidad dada por:

\[
p_X(x) = \begin{cases}
1/10 & x = -2, \\
2/10 & x = -1, \\
3/10 & x = 1, \\
4/10 & x = 2, \\
0 & \text{en otros casos.}
\end{cases}
\]

Con esta variable aleatoria $X$, cada resultado en el espacio  muestral, es asignado  a uno de los cuatro n\'umeros reales $-2, -1, 1$ \'o $2$. Consideramos  la variable aleatoria derivada $Y = X^2$. En este caso, cada resultado se le asigna  $1$ \'o  $4$. Si $X$ asigna un resultado  $-1$ \'o $1$ , entonces $Y$ asignar\'a ese resultado a $1$, mientras que si $X$ asigna un resultado a $-2$ \'o $2$, entonces $Y$ asignar\'a ese resultado a $4$.

\vspace{0.2cm}

La variable aleatoria $Y$ tiene la siguiente funci\'on de masa de probabilidad, que no es la misma que  la de $X$:

\[
p_y(y) = \begin{cases}
2/10 + 3/10  & y = 1, \\
1/10 +  4/10 & y = 4, \\
0 & \text{en otros casos.}
\end{cases}
\]
\end{ejemplo}

\vspace{0.2cm}

Estos ejemplos ilustran la regla de que la funci\'on de masa de probabilidad de una variable aleatoria de  $Y$ , que es una funci\'on de una variable aleatoria $X$, es igual a la funci\'on de masa de probabilidad de $X$, si $g(x_1)\neq g(x_2)$ cuando $x_1 \neq x_2$. De lo contrario la funci\'on de masa de probabilidad de $Y$ se obtiene de la relaci\'on general (general en el sentido de que tambi\'en cubre el caso anterior):

\[
p_Y(y) = \sum_{x: g(x)= y}p_{X}(x).
\]

\vspace{0.2cm}
Aqu\'i la suma es sobre todos los $x$, para el cu\'al $g(x) = y$.

\vspace{0.3cm}

\begin{ejemplo}
\normalfont Sea $X$ una variable aleatoria discreta, que es definida sobre los enteros en el intervalo $[-3, 4]$. Sea la funci\'on de masa de probabilidad de $X$:

\[
p_X(x) = \begin{cases}
0.05 & x \in \{-3, 4 \}, \\
0.10 & x \in \{-2, 3\}, \\
0.15 & x \in  \{ -1,2\}, \\
0.20 & x \in  \{0, 1\}, \\
0 & \text{en otros casos.}
\end{cases}
\]

Encontremos la funci\'on de masa de probabilidad  de la variable aleatoria $Y$, definida como $Y = X^2 -\vert X \vert$.

\vspace{0.2cm}

Como los posibles valores de $X$ son dados por $[-3, -2, -1, 0, 1, 2, 3, 4]$, se sigue que los valores de $Y$ son $[6, 2, 0, 0, 0, 2, 6, 12]$ y as\'i el rango de $Y$ es $[0,2,6, 12]$. Esto permite calcular la funci\'on de masa de probabilidad de $Y$ como:

\[
p_Y(y) = \begin{cases}
0.15 + 0.20 + 0.20 = 0.55 & \text{si}\ y = 0 \ \ \  (g(x) = y \ \text{para}\  x = -1,0,1)\\
0.10 + 0.15 = 0.25 & \text{si}\  y = 2\ \ \  (g(x) = y \ \text{para}\ x = -2,2),\\
0.05 + 0.10 = 0.15 & \text{si}\ y =6 \ \ \ (g(x) = y \ \text{para}\ x = -3,3), \\
0.05 = 0.05 & \text{si} \ y =12 \ \ \ (g(x) = y \ \text{para}\ x = 4),\\
0 & \text{en otros casos.}
\end{cases}
\]
\end{ejemplo}

\begin{ejemplo}
\normalfont Continuando con el \texttt{Ejemplo 2.2}, sea $D$ la distancia de la part\'icula, desde el origen despu\'es de $n$ pasos. Asumiendo  que $n$ es par. Encontremos el PMF de $D$.

\vspace{0.2cm}

Podemos escribir $D = \vert Y \vert$, esta es una funci\'on de $Y$, pero no es inyectiva. El evento $D =0$, es el mismo que el evento $Y = 0$. Para $k = 2, 4,\dots, n$, el evento $D = k$ es el mismo evento $\{ Y = k\} \cup \{Y = -k\}$. 


\vspace{0.2cm}


As\'i el PMF de $D$ es:

\begin{align*}
\mathbb{P}(D = 0) &= \binom{n}{\frac{n}{2}}\biggl(\frac{1}{2}\biggr),\\
\mathbb{P}(D = k) &= \mathbb{P}(Y = k) + \mathbb{P}(Y = -k) = 2\binom{n}{\frac{n +k}{2}}\biggl(\frac{1}{2}\biggr),
\end{align*}

para $k = 2, 4,\dots, n$. En el paso final, usamos la simetria para ver que $\mathbb{P}(Y =k) = \mathbb{P}(Y = -k)$. 
\end{ejemplo}

\vspace{0.3cm}

En el caso de variables aleatorias continuas, un enfoque es empezar con la funci\'on de distribuci\'on acumulativa  de $g(X)$ y trasladar  el evento $g(X) \leq y$ en un evento equivalente que implica $X$. Para una funci\'on general $g$, debemos expresar de forma acertada  $g(X) \leq y$ en t\'erminos de $X$ y no hay una f\'ormula f\'acil para eso. Pero cuando $g$ es continua y estrictamente creciente, podemos encontrar una expresi\'on conveniente, si  $g(X) \leq y $ es lo mismo que $X \leq g^{-1}(y)$ y  as\'i tenemos que:

\vspace{0.2cm}

\[
F_{g(X)}(y) = \mathbb{P}(g(X) \leq y) = \mathbb{P}(X \leq g^{-1}(y)) = F_{X}(g^{-1}y).
\]

\vspace{0.2cm}

Entonces podemos diferenciar con respecto a $y$ para obtener el PDF de $g(X)$. Esto da una versi\'on unidimensional de la f\'ormula de cambio de variables, que se generaliza a transformaciones invertibles en m\'ultiples dimensiones.

\vspace{0.2cm}

\begin{teo}
\normalfont Sea $X$ una variable aleatoria continua con PDF $f_X$ y sea $Y = g(X)$, donde $g$ es diferenciable y estrictamente creciente (o estrictamente creciente). Entonces el PDF de $Y$ es dado por:

\[
f_Y(y) = f_X(x)\biggl\vert\frac{dx}{dy} \biggr\vert,
\]

donde $x = g^{-1}(y)$.
\end{teo}

\vspace{0.2cm}

Sea $g$  una funci\'on estrictamente creciente. El CDF de Y es:

\[
F_{Y}(y) = \mathbb{P}(Y \leq y) = \mathbb{P}(g(X) \leq y) = \mathbb{P}(X \leq g^{-1}(y)) = F_{X}(g^{-1}(y)) = F_X(x),
\]

\vspace{0.2cm}

As\'i por la regla de la cadena, el PDF de $Y$ es:

\[
f_Y(y) = f_X(x)\frac{dx}{dy}.
\]

La prueba  para $g$ estrictamente decreciente es an\'alogo. En ese caso el PDF, termina como, $-f_X(x)\frac{dx}{dy}$, que no es negativa, desde que $\frac{dx}{dy} < 0$ si $g$ es estrictamente decreciente. Usando $\biggl\vert\frac{dx}{dy} \biggr\vert$ como en la declaraci\'on del teorema, abarca ambos casos.

\vspace{0.2cm}


\begin{defi}
\normalfont El soporte de una variable aleatoria continua $X$ y su distribuci\'on, es el conjunto de todos los puntos $x$ donde $f_X(x) > 0$.
\end{defi}

\vspace{0.2cm}
\begin{ejemplo}
\normalfont La funci\'on de distribuci\'on acumulativa de una variable aleatoria exponencial $X$ con param\'etro $\lambda$ es dado por:

\[
\mathbb{P}(X \leq x) = \begin{cases}
1 - e^{-\lambda x}, & \  x\geq 0 \\
0 & \text{ en otro caso.}
\end{cases}
\]

\vspace{0.2cm}

Calculemos la funci\'on de distribuci\'on acumulativa y la funci\'on de densidad de una variable aleatoria $Y$, definida como $Y = X^2$. Nosotros tenemos:

\[
\mathbb{P}(Y \leq y) = \mathbb{P}(X^2 \leq y) = \mathbb{P}(X \leq \sqrt{y}) = 1 -e^{-\lambda \sqrt{y}}\ \ \text{para}\ y \geq 0.
\]

\vspace{0.2cm}

Podemos calcular la funci\'on densidad de $Y$, por diferenciaci\'on. As\'i tenemos:

\vspace{0.2cm}

\[
f_Y(y) = \frac{d}{dy}\mathbb{P}(Y \leq y) = \lambda e^{-\lambda y^{1/2}}\times \frac{1}{2}y^{-1/2} = \frac{\lambda}{2\sqrt{y}}e^{-\lambda \sqrt{y}}\ \ \text{para}\ y > 0.
\]

\vspace{0.2cm}

En experimentos de simulaci\'on es frecuente que se tenga acceso a secuencias de n\'umeros aleatorios que se distribuyen uniformemente en el intervalo $(0,1)$, pero lo que realmente se requiere son n\'umeros aleatorios de una distribuci\'on no uniforme. En particular, en teoria  de colas, a menudo se necesitan n\'umeros aleatorios que se distribuyen de acuerdo con una distribuci\'on exponencial (negativa). Este \'ultimo ejemplo muestra c\'omo se pueden obtener tales n\'umeros.
\end{ejemplo}

\vspace{0.2cm}

\begin{ejemplo}
\normalfont Sea $X \sim N(0,1), Y = e^X$. Usemos el teorema de cambio de variable para encontrar el PDF de $Y$, desde que $g(x) = e^X$ es estrictamente creciente. Sea $y = e^X$, As\'i $x = \log y$ y $dy/dx = e^x$. Entonces:

\[
f_Y(y) = f_X(x)\biggl\vert \frac{dx}{dy} \biggr\vert = \varphi(x)\frac{1}{e^x} = \varphi(\log y)\frac{1}{y}, \ y > 0.
\]

\vspace{0.2cm}

Ten en cuenta que despu\'es de aplicar la f\'ormula de cambio de variables, escribimos todo a la derecha en t\'erminos de $y$ y especificamos el soporte \footnote{Si $X$ es una variable aleatoria discreta, el conjunto finito o infinito contable de valores $x$ tal que $\mathbb{P}(X = x)> 0$, es llamado soporte de $X$.} de la distribuci\'on. Para determinar el soporte, s\'olo observamos que cuando $x$ var\'ia desde $-\infty$ a $\infty$, $e^X$ var\'ia desde $0$ a $\infty$.

\vspace{0.2cm}

Podemos obtener el mismo resultado trabajando a partir de la definici\'on de la funci\'on de distribuci\'on acumulativa, transladando el evento $Y \leq y$ en un evento equivalente involucrando $X$. Para $y> 0$,

\[
F_Y(y) = \mathbb{P}(Y \leq y) = \mathbb{P}(e^X \leq y) = \mathbb{P}(X \leq \log y) = \Phi(\log y),
\]

\vspace{0.2cm}

y as\'i el PDF, otra vez es:

\[
f_Y(y) = \frac{d}{dy}\Phi(\log Y) = \varphi(\log y)\frac{1}{y}, \ y> 0.
\]
\end{ejemplo}

\vspace{0.2cm}

\begin{ejemplo}
\normalfont Sea la funci\'on densidad de probabilidad de una variable aleatoria $X$, es dado por:

\[
f_X(x) = \begin{cases}
\alpha/x^5, & 1 \leq x < \infty \\
0 & \text{en otros casos.}
\end{cases}
\]

Sea una nueva variable aleatoria definida como $Y = 1/X$. Encontremos la funci\'on densidad de $Y$.

\vspace{0.2cm}

Primero responderemos a la pregunta usando el enfoque est\'andar. Nuestra primera tarea es calcular el valor de $\alpha $. Ya que debemos tener:

\[
1 = \bigints_{-\infty}^{\infty}f_X(x) dx = \bigints_{1}^{\infty}\frac{\alpha}{x^5} dx= -\alpha\frac{x^{-4}}{4}\biggl\vert_{1}^{\infty} = \frac{\alpha}{4},
\]

y por propiedad $\alpha = 4$. La funci\'on distribuci\'on acumulativa de $X$, ahora se puede calcular como:

\[
F_X(x) = \bigints_{1}^{x}f_X(t)dt = \bigints_{1}^{x}\frac{4}{t^5}dt = -t^{-4}\biggl\vert_{1}^{x} = 1 - \frac{1}{x^4}, \ x\geq 1.
\]

\vspace{0.2cm}

Ahora, usando probabilidades y observando que el rango de $Y$ es $(0, 1]$, podemos calcular la distribuci\'on acumulativa de $Y$ como:

\vspace{0.2cm}

\[
\mathbb{P}(Y \leq y) = \mathbb{P}(1/X \leq y) = \mathbb{P}(X \geq 1/y) = 1 -\mathbb{P}(X < 1/y) = 1 -F_X(1/y) = y^4, \ \text{para}\ \ 0 < Y \leq 1.
\]

\vspace{0.2cm}

Finalmente, calculamos la funci\'on densidad de $Y$, tomando derivadas. As\'i obtenemos:

\vspace{0.2cm}

\[
f_Y(y) = \frac{d}{dy}F_Y(y) = \frac{d}{dy}y^4 = 4y^3, \ 0 < y \leq 1.
\]

\vspace{0.2cm}

Utilizando el teorema de cambio de variables, cuando $y = 1/x$ y as\'i $x = 1/y$, obtenemos 

\[
f_Y(y) = \frac{4}{(1/y)^5}\biggl\vert \frac{-1}{y^2}\biggr\vert = 4y^3 
\]

como antes. 
\end{ejemplo}

\vspace{0.2cm}

\begin{ejemplo}
\normalfont Sea $X$ una variable aleatoria continua con PDF, $f_X$ y sea $Y = a +bX$, con $b \neq 0$. Sea $y = a +bx$, el espejo de la relaci\'on entre $Y$ y $X$. Entonces $\frac{dy}{dx} = b$ y as\'i el PDF de $Y$ es:

\vspace{0.2cm}

\[
f_Y(y) = f_X(x)\biggl\vert \frac{dx}{dy}\biggr\vert = f_X\biggl(\frac{y -a}{b}\biggr)\frac{1}{\vert b \vert}.
\]
\end{ejemplo}
\end{document}
